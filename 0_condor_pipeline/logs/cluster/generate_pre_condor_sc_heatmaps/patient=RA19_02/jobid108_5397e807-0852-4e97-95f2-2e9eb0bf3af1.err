Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 4
Rules claiming more threads will be scaled down.
Provided resources: mem_mb=8000, mem_mib=7630, disk_mb=1000, disk_mib=954, time_min=59
Select jobs to execute...

[Fri Jul 19 13:14:41 2024]
rule generate_pre_condor_sc_heatmaps:
    input: /data/iacobuzc/haochen/Tapestri_main_manuscript_analysis/data_compiled/fillout_h5/RA19_02.patient_wide.genotyped.h5, /data/iacobuzc/haochen/Tapestri_main_manuscript_analysis/data_compiled/falcon_solutions/RA19_02.sample_sc_clone_assignment.updated.csv, /lila/data/iacobuzc/haochen/Tapestri_main_manuscript_analysis/data_compiled/manual_annotated_snv_lists/RA19_02-patient-all_vars-voi.hz_curated.txt
    output: pre_condor_sc_heatmaps/RA19_02_DNA_heatmap.pdf
    log: pre_condor_sc_heatmaps/logs/RA19_02_heatmap.log, pre_condor_sc_heatmaps/logs/RA19_02_heatmap.err.log
    jobid: 0
    reason: Missing output files: pre_condor_sc_heatmaps/RA19_02_DNA_heatmap.pdf
    wildcards: patient=RA19_02
    threads: 4
    resources: mem_mb=8000, mem_mib=7630, disk_mb=1000, disk_mib=954, tmpdir=/scratch/lsftmp/8216996.tmpdir, time_min=59

Activating conda environment: mosaic
[Fri Jul 19 13:15:57 2024]
Finished job 0.
1 of 1 steps (100%) done
