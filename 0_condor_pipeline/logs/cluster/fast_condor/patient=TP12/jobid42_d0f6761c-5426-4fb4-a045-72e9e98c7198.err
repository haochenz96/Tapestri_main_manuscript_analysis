Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 16
Rules claiming more threads will be scaled down.
Provided resources: mem_mb=1000, mem_mib=954, disk_mb=1000, disk_mib=954, mem_gb=16, time_min=238
Select jobs to execute...

[Fri Jul 19 13:25:47 2024]
rule fast_condor:
    input: condor_inputs/TP12/character_bin_matrix.csv, condor_inputs/TP12/alt_readcounts.csv, condor_inputs/TP12/total_readcounts.csv, condor_inputs/TP12/germline_mutations.txt, condor_inputs/TP12/somatic_mutations.txt, /data/iacobuzc/haochen/Tapestri_main_manuscript_analysis/data_compiled/falcon_solutions/TP12_homdel_nclones=6.unique_cn_clone_profiles.csv
    output: condor_outputs/TP12/out_tree.newick, condor_outputs/pickle_files/TP12_self.solT_cell
    log: condor_outputs/TP12/condor_outputs.log, condor_outputs/TP12/condor_outputs.err.log
    jobid: 0
    reason: Missing output files: condor_outputs/TP12/out_tree.newick, condor_outputs/pickle_files/TP12_self.solT_cell
    wildcards: patient=TP12
    threads: 16
    resources: mem_mb=1000, mem_mib=954, disk_mb=1000, disk_mib=954, tmpdir=/scratch/lsftmp/8217257.tmpdir, mem_gb=16, time_min=238

Activating conda environment: condor
[Fri Jul 19 13:26:03 2024]
Error in rule fast_condor:
    jobid: 0
    input: condor_inputs/TP12/character_bin_matrix.csv, condor_inputs/TP12/alt_readcounts.csv, condor_inputs/TP12/total_readcounts.csv, condor_inputs/TP12/germline_mutations.txt, condor_inputs/TP12/somatic_mutations.txt, /data/iacobuzc/haochen/Tapestri_main_manuscript_analysis/data_compiled/falcon_solutions/TP12_homdel_nclones=6.unique_cn_clone_profiles.csv
    output: condor_outputs/TP12/out_tree.newick, condor_outputs/pickle_files/TP12_self.solT_cell
    log: condor_outputs/TP12/condor_outputs.log, condor_outputs/TP12/condor_outputs.err.log (check log file(s) for error details)
    conda-env: condor
    shell:
        
		python /data/iacobuzc/haochen/Tapestri_batch2/analysis/full-ConDoR/fast-ConDoR/src/fast-condor.py 			-i condor_inputs/TP12/character_bin_matrix.csv 			-r condor_inputs/TP12/total_readcounts.csv 			-v condor_inputs/TP12/alt_readcounts.csv 			-s condor_inputs/TP12/germline_mutations.txt 			-s2 condor_inputs/TP12/somatic_mutations.txt 			-o condor_outputs/TP12/out 			-m /data/iacobuzc/haochen/Tapestri_batch2/analysis/full-ConDoR/references/panel3559_analysis.gene_cytoband.formatted.manual_adjusted.gene_pos_ado_added.csv 			-d TP12 			--scr 			--cnp /data/iacobuzc/haochen/Tapestri_main_manuscript_analysis/data_compiled/falcon_solutions/TP12_homdel_nclones=6.unique_cn_clone_profiles.csv 			--subclonal_mutations /data/iacobuzc/haochen/Tapestri_main_manuscript_analysis/data_compiled/manual_subclonal_snvs/TP12.subclonal_mutations.yaml 			1> condor_outputs/TP12/condor_outputs.log 2> condor_outputs/TP12/condor_outputs.err.log
		
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

Trying to restart job 0.
Select jobs to execute...

[Fri Jul 19 13:26:03 2024]
rule fast_condor:
    input: condor_inputs/TP12/character_bin_matrix.csv, condor_inputs/TP12/alt_readcounts.csv, condor_inputs/TP12/total_readcounts.csv, condor_inputs/TP12/germline_mutations.txt, condor_inputs/TP12/somatic_mutations.txt, /data/iacobuzc/haochen/Tapestri_main_manuscript_analysis/data_compiled/falcon_solutions/TP12_homdel_nclones=6.unique_cn_clone_profiles.csv
    output: condor_outputs/TP12/out_tree.newick, condor_outputs/pickle_files/TP12_self.solT_cell
    log: condor_outputs/TP12/condor_outputs.log, condor_outputs/TP12/condor_outputs.err.log
    jobid: 0
    reason: Missing output files: condor_outputs/TP12/out_tree.newick, condor_outputs/pickle_files/TP12_self.solT_cell
    wildcards: patient=TP12
    threads: 16
    resources: mem_mb=1000, mem_mib=954, disk_mb=1000, disk_mib=954, tmpdir=/scratch/lsftmp/8217257.tmpdir, mem_gb=16, time_min=238

Activating conda environment: condor
[Fri Jul 19 13:26:07 2024]
Error in rule fast_condor:
    jobid: 0
    input: condor_inputs/TP12/character_bin_matrix.csv, condor_inputs/TP12/alt_readcounts.csv, condor_inputs/TP12/total_readcounts.csv, condor_inputs/TP12/germline_mutations.txt, condor_inputs/TP12/somatic_mutations.txt, /data/iacobuzc/haochen/Tapestri_main_manuscript_analysis/data_compiled/falcon_solutions/TP12_homdel_nclones=6.unique_cn_clone_profiles.csv
    output: condor_outputs/TP12/out_tree.newick, condor_outputs/pickle_files/TP12_self.solT_cell
    log: condor_outputs/TP12/condor_outputs.log, condor_outputs/TP12/condor_outputs.err.log (check log file(s) for error details)
    conda-env: condor
    shell:
        
		python /data/iacobuzc/haochen/Tapestri_batch2/analysis/full-ConDoR/fast-ConDoR/src/fast-condor.py 			-i condor_inputs/TP12/character_bin_matrix.csv 			-r condor_inputs/TP12/total_readcounts.csv 			-v condor_inputs/TP12/alt_readcounts.csv 			-s condor_inputs/TP12/germline_mutations.txt 			-s2 condor_inputs/TP12/somatic_mutations.txt 			-o condor_outputs/TP12/out 			-m /data/iacobuzc/haochen/Tapestri_batch2/analysis/full-ConDoR/references/panel3559_analysis.gene_cytoband.formatted.manual_adjusted.gene_pos_ado_added.csv 			-d TP12 			--scr 			--cnp /data/iacobuzc/haochen/Tapestri_main_manuscript_analysis/data_compiled/falcon_solutions/TP12_homdel_nclones=6.unique_cn_clone_profiles.csv 			--subclonal_mutations /data/iacobuzc/haochen/Tapestri_main_manuscript_analysis/data_compiled/manual_subclonal_snvs/TP12.subclonal_mutations.yaml 			1> condor_outputs/TP12/condor_outputs.log 2> condor_outputs/TP12/condor_outputs.err.log
		
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
