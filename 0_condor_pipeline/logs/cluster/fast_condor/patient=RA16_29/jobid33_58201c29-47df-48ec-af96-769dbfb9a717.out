Sender: LSF System <lsfadmin@ls13>
Subject: Job 8217024: <fast_condor.patient=RA16_29> in cluster <lila> Exited

Job <fast_condor.patient=RA16_29> was submitted from host <lt03> by user <zhangh5> in cluster <lila> at Fri Jul 19 13:16:06 2024
Job was executed on host(s) <4*ls13>, in queue <cpuqueue>, as user <zhangh5> in cluster <lila> at Fri Jul 19 13:16:08 2024
</home/zhangh5> was used as the home directory.
</lila/data/iacobuzc/haochen/condor_pipeline_trial> was used as the working directory.
Started at Fri Jul 19 13:16:08 2024
Terminated at Fri Jul 19 13:17:38 2024
Results reported at Fri Jul 19 13:17:38 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
/lila/data/iacobuzc/haochen/condor_pipeline_trial/.snakemake/tmp.e3awy4tj/snakejob.fast_condor.33.sh
------------------------------------------------------------

TERM_MEMLIMIT: job killed after reaching LSF memory usage limit.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   66.63 sec.
    Max Memory :                                 4 GB
    Average Memory :                             1.11 GB
    Total Requested Memory :                     4.00 GB
    Delta Memory :                               0.00 GB
    Max Swap :                                   -
    Max Processes :                              7
    Max Threads :                                12
    Run time :                                   90 sec.
    Turnaround time :                            92 sec.

The output (if any) follows:



PS:

Read file <logs/cluster/fast_condor/patient=RA16_29/jobid33_58201c29-47df-48ec-af96-769dbfb9a717.err> for stderr output of this job.

